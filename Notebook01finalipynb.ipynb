{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Yd5hQALEOzbs-xQQHQOFw1R_zv6qUqjm",
      "authorship_tag": "ABX9TyPx8/DWdCYo7fg6QbO4f5ma",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thaheshan/Breast_Cancer_Prediction_Model/blob/main/Notebook01finalipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Title: Notebook 1 - Data Preprocessing for Cancer Survival Analysis code snippet\n",
        "# Author: Suresh Thaheshan\n",
        "# Peer Reviewer: Ayman Jaleel\n",
        "# Date: May 3, 2025\n",
        "\n",
        "\n",
        "# IMPORT LIBRARIES\n",
        "# Import the libraries for the necessary inputs related to the data cleaning aand preprocessing method\n",
        "\n",
        "#code reuse for import from notebok 01 reuse\n",
        "#import pandas library\n",
        "#which is very important for loading te datset , cleaning and manipulation\n",
        "#it will manipulate the dataset and analyze the survival prediction\n",
        "import pandas as pd\n",
        "\n",
        "#import numpy library for thenumerical operation\n",
        "#it is usefuk for calculations in math opeartions\n",
        "import numpy as np\n",
        "\n",
        "#import mathplotlib for the creative visualizaations\n",
        "#it will give the data analysis in visualization graph and tables\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#import seadborn to use this with matplotlib library\n",
        "#it will be helpul for, statistical graaphic and for the distribution plots\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n"
      ],
      "metadata": {
        "id": "T7SZgO_HThZU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the viualization style with seaborn and mathplotlib libraries\n",
        "#giving a white grid for the visualization and diifferentiation\n",
        "sns.set_style('whitegrid')\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "\n",
        "\n",
        "# Define  aa saving path for the data preprocessed tables\n",
        "save_path = '/content/drive/MyDrive/Machine_Learning_CourseWork'\n",
        "#using os to run it with windows and if the file path exist true pass it t the aave_path variable to save through the path\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "#LOAD the given DATA\n",
        "#load the given data for the survival predictions\n",
        "#mount it to the google drive and load he dataset\n",
        "print(\"Loading the dataset from file!\")\n",
        "df = pd.read_csv('/content/drive/MyDrive/Machine_Learning_CourseWork/5DATA002W.2 Coursework Dataset(25012025v6.0) (2).csv')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_xoZ0m7E4C3",
        "outputId": "8e7fdc4b-0b5a-476f-ea19-175cdca783b2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading the dataset from file!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  INITIAL STARTING STAGE EXPLORATION\n",
        "#check the sample dataset\n",
        "#use this for, verify the datset loaded properly!\n",
        "#ensure what kinf=d of data , we are going to work with here\n",
        "#ideni=tify the missing null values and the wrong data informations\n",
        "#have duplicate columns\n",
        "print(\"\\nDataset Preview sample:\")\n",
        "print(df.head())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_7TbmIWJtej",
        "outputId": "a366be61-0cdc-4c3b-918d-ac994bd6ada0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset Preview sample:\n",
            "  Patient_ID  Month_of_Birth   Age     Sex   Occupation T_Stage N_Stage  \\\n",
            "0      A0012              12  68.0  Female     Teaching      T1      N1   \n",
            "1      A0013              12  50.0  Female      Medical      T2      N2   \n",
            "2      A0014              11  58.0  Female  Engineering      T3      N3   \n",
            "3      A0015               3  58.0  Female   Technology      T1      N1   \n",
            "4      A0016               1  47.0  Female   Multimedia      T2      N1   \n",
            "\n",
            "  6th_Stage             Differentiated  Grade   A_Stage  Tumor_Size  \\\n",
            "0       IIA      Poorly differentiated      3  Regional         4.0   \n",
            "1      IIIA  Moderately differentiated      2  Regional        35.0   \n",
            "2      IIIC  Moderately differentiated      2  Regional        63.0   \n",
            "3       IIA      Poorly differentiated      3  Regional        18.0   \n",
            "4       IIB      Poorly differentiated      3  Regional        41.0   \n",
            "\n",
            "  Estrogen_Status Progesterone_Status  Regional_Node_Examined  \\\n",
            "0        Positive            Positive                    24.0   \n",
            "1        Positive            Positive                    14.0   \n",
            "2        Positive            Positive                    14.0   \n",
            "3        Positive            Positive                     2.0   \n",
            "4        Positive            Positive                     3.0   \n",
            "\n",
            "   Reginol_Node_Positive  Survival_Months Mortality_Status  \n",
            "0                      1               60            Alive  \n",
            "1                      5               62            Alive  \n",
            "2                      7               75            Alive  \n",
            "3                      1               84            Alive  \n",
            "4                      1               50            Alive  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#the shape element in pandas library\n",
        "#i used to call it from the dataset path\n",
        "#it will analyze and give the number of rows and number of cloumns haveing on the dataset\n",
        "#resure from notebook 01 reuse session\n",
        "#resue from notebook 01\n",
        "print(\"\\n Dataset columns and rows:\", df.shape)\n",
        "\n",
        "#use dftypes to check what are the data tyoes contains in each column\n",
        "print(\"\\nData Types in each columns :\")\n",
        "print(df.dtypes)\n",
        "\n",
        "\n",
        "#use df describe elemnet for give statistics to numeric value contained columns\n",
        "#it will give the analyss as count min  std , percentage comparison and max\n",
        "print(\"\\nBasic Statistics:\")\n",
        "print(df.describe())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erTDesBBLdmX",
        "outputId": "24e235da-d147-49d7-ad88-385f7ec06b05"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Dataset columns and rows: (4024, 18)\n",
            "\n",
            "Data Types in each columns :\n",
            "Patient_ID                 object\n",
            "Month_of_Birth              int64\n",
            "Age                       float64\n",
            "Sex                        object\n",
            "Occupation                 object\n",
            "T_Stage                    object\n",
            "N_Stage                    object\n",
            "6th_Stage                  object\n",
            "Differentiated             object\n",
            "Grade                       int64\n",
            "A_Stage                    object\n",
            "Tumor_Size                float64\n",
            "Estrogen_Status            object\n",
            "Progesterone_Status        object\n",
            "Regional_Node_Examined    float64\n",
            "Reginol_Node_Positive       int64\n",
            "Survival_Months             int64\n",
            "Mortality_Status           object\n",
            "dtype: object\n",
            "\n",
            "Basic Statistics:\n",
            "       Month_of_Birth          Age        Grade   Tumor_Size  \\\n",
            "count     4024.000000  4015.000000  4024.000000  4021.000000   \n",
            "mean         6.481362    54.107098     2.150596    30.419299   \n",
            "std          3.475442    11.715528     0.638234    21.161080   \n",
            "min          1.000000   -50.000000     1.000000   -75.000000   \n",
            "25%          3.000000    47.000000     2.000000    16.000000   \n",
            "50%          6.000000    54.000000     2.000000    25.000000   \n",
            "75%         10.000000    61.000000     3.000000    38.000000   \n",
            "max         12.000000   502.000000     4.000000   140.000000   \n",
            "\n",
            "       Regional_Node_Examined  Reginol_Node_Positive  Survival_Months  \n",
            "count             4023.000000            4024.000000      4024.000000  \n",
            "mean                14.373602               4.158052        71.472167  \n",
            "std                  8.129293               5.109331        25.361855  \n",
            "min                  1.000000               1.000000         1.000000  \n",
            "25%                  9.000000               1.000000        56.000000  \n",
            "50%                 14.000000               2.000000        73.000000  \n",
            "75%                 19.000000               5.000000        90.000000  \n",
            "max                 61.000000              46.000000       760.000000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  DATA CLEANING process for null\n",
        "print(\"\\n= DATA CLEANING process \")\n",
        "\n",
        "#  first Check for missing values in null mat\n",
        "#df isnull element wil;l check which columns has the null value or empty value\n",
        "#it will chek aand give boolean type total for how many null value exist in column by column\n",
        "print(\"\\nMissing Values Before Handling:\")\n",
        "print(df.isnull().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKfBAs6cPDKH",
        "outputId": "82f607d3-c135-4178-f08d-b88dd1cf15a4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "= DATA CLEANING process \n",
            "\n",
            "Missing Values Before Handling:\n",
            "Patient_ID                   0\n",
            "Month_of_Birth               0\n",
            "Age                          9\n",
            "Sex                          4\n",
            "Occupation                3981\n",
            "T_Stage                      0\n",
            "N_Stage                      0\n",
            "6th_Stage                    0\n",
            "Differentiated               0\n",
            "Grade                        0\n",
            "A_Stage                      0\n",
            "Tumor_Size                   3\n",
            "Estrogen_Status              0\n",
            "Progesterone_Status          0\n",
            "Regional_Node_Examined       1\n",
            "Reginol_Node_Positive        0\n",
            "Survival_Months              0\n",
            "Mortality_Status             0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#the fillna will be aapplicable for flat values\n",
        "#becaause it calcukate median for outliers\n",
        "#here we can seu fillna for two columns missing values\n",
        "#which are age and tumor_size\n",
        "\n",
        "\n",
        "#Since, these data we can get the\n",
        "#i can see thre are 9 missing values in the age column\n",
        "#  so Handle missing values\n",
        "# Fix missing Age\n",
        "#fix it with fillna element in pandas library\n",
        "#it has missing values (outliers)\n",
        "#which will automatically fillout the places\n",
        "#it will fillout the details automatically from calculate the median between the missing values\n",
        "#wil give the middle value of the sorted data\n",
        "\n",
        "df['Age'] = df['Age'].fillna(df['Age'].median())\n",
        "\n",
        "\n",
        "# Drop rows with missing Tumor_Size\n",
        "df = df.dropna(subset=['Tumor_Size'])"
      ],
      "metadata": {
        "id": "HLw9Bs1TP0Ew"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for any other critical columns with missing values\n",
        "# These columns are important for analysis and should not have missing values\n",
        "#for a brast cancer analysis, the stages analysis and sttaus analysis and survival months given in the reports need as fundamental data for this\n",
        "critical_columns = ['T_Stage', 'N_Stage', '6th_Stage', 'Grade',\n",
        "              'Estrogen_Status', 'Progesterone_Status',  'Survival_Months', 'Mortality_Status']\n",
        "\n",
        "# Remove rows where any of the critical columns have missing values\n",
        "# dropna() is used from pandas to drop the rows\n",
        "# subset=critical_columns means we are only checking these specific columns for NaN\n",
        "# if any one of these has a missing value, that whole row will be removed\n",
        "# this is done because these columns are critical for survival and stage analysis\n",
        "# and we can't afford to work with incomplete data in these columns for the futher prediction\n",
        "df = df.dropna(subset=critical_columns)\n"
      ],
      "metadata": {
        "id": "wVG-xKZ4TXnB"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show the missing values after we cleaned the data\n",
        "\n",
        "\n",
        "# isnull().sum() will cheak how many missing values are there now\n",
        "\n",
        "print(\"\\nMissing Values After Handling:\")\n",
        "print(df.isnull().sum())\n",
        "# it will return the count of nulls in each column\n",
        "\n",
        "# now it should be low or 0 in the colums we handled befre\n",
        "# we use this to confirm we fixed the missing value issue\n",
        "# if still missing then need to fix more or check again"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkBRpV9kT50r",
        "outputId": "3c340371-9771-40f4-9652-dace61d6bf9a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Missing Values After Handling:\n",
            "Patient_ID                   0\n",
            "Month_of_Birth               0\n",
            "Age                          0\n",
            "Sex                          4\n",
            "Occupation                3978\n",
            "T_Stage                      0\n",
            "N_Stage                      0\n",
            "6th_Stage                    0\n",
            "Differentiated               0\n",
            "Grade                        0\n",
            "A_Stage                      0\n",
            "Tumor_Size                   0\n",
            "Estrogen_Status              0\n",
            "Progesterone_Status          0\n",
            "Regional_Node_Examined       1\n",
            "Reginol_Node_Positive        0\n",
            "Survival_Months              0\n",
            "Mortality_Status             0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DATA TRANSFORMATION method\n",
        "print(\" DATA TRANSFORMATION PROCESS \")\n",
        "\n",
        "# we use data transformation to make the data more redy for machine lerning or analysis progress\n",
        "# after cleaning the null values we still have some things to fix like categorial values or scales\n",
        "\n",
        "# some columns may have text like \"Low\", \"Medium\", \"High\" which machine cant understand\n",
        "\n",
        "\n",
        "# categorial values mens the columns which have text or lables instead of numbers\n",
        "# like \"Male\" and \"Female\" or \"Low\", \"Medium\", \"High\" or \"Yes\", \"No\"\n",
        "\n",
        "\n",
        "# we use abs() function to remove all negtive values and makes then positive\n",
        "# abs means absolute value (like |-5| becomes 5)\n",
        "\n",
        "# some columns like Age, Tumor_Size, Regional_Node_Examined cannot be negative in real life\n",
        "# so maybe during the data entry or system error it was saved as negative number\n",
        "# we use abs() to fix this issue and keep data logical and clean\n",
        "# otherwise wrong values like -45 age will give problem during analysis\n",
        "df['Age'] = df['Age'].abs()\n",
        "df['Tumor_Size'] = df['Tumor_Size'].abs()\n",
        "df['Regional_Node_Examined'] = df['Regional_Node_Examined'].abs()\n",
        "\n",
        "\n",
        "# Fix: Corrected column name from Regional_Node_Positive to Reginol_Node_Positive\n",
        "df['Regional_Node_Positive'] = df['Regional_Node_Positive'].abs()\n",
        "df['Survival_Months'] = df['Survival_Months'].abs()\n",
        "\n",
        "\n",
        "# so we need to convert them to numbers (like 0,1,2) this is called encoding\n",
        "\n",
        "# also sometimes the values are in diffrent range like Age is 20-80 and Salary is 10000-90000\n",
        "# this can confuse ssome algortms so we use normalization or scaling\n",
        "# also we might want to create new columns or modify existing one (like combine 2 columns)\n",
        "\n",
        "# all these steps called data transformation to make the data more powerfull and machine frendly\n",
        "\n",
        "# check and Fix invalid values\n",
        "# Fix negative values\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQvc4NXDUv6x",
        "outputId": "acd0d366-2011-4477-b521-064fe2a91b2f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " DATA TRANSFORMATION PROCESS \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter out outliers (mising values )\n",
        "df = df[df['Age'] <= 100]\n",
        "# we are removing data where age is more than 100 becoz its too high and may be invalid\n",
        "# maybe some data entry mistake or very rare case so beter to remove it for clean the data\n",
        "#it will help to give better resukts\n",
        "\n",
        "# this helps model to not get confused by strange values\n",
        "# Age constraint differenciation – we keep age in a normal human range\n",
        "\n",
        "# Create age groups\n",
        "df['Age_Group'] = pd.cut(df['Age'],\n",
        "                          bins=[0, 40, 60, 100],\n",
        "                          labels=['Young', 'Middle', 'Senior'])\n",
        "# we use pd.cut elemnt  to split the Age column into 3 parts (or buckets)\n",
        "\n",
        "# from 0 to 40 it's called 'Young', 41 to 60 is 'Middle', and 61 to 100 is 'Senior'\n",
        "\n",
        "\n",
        "# this help us to group ppl into age catagories which is easier to anlyze\n",
        "# now instead of many values we have 3 clear group lables\n",
        "\n",
        "# Ensure Mortality_Status is correctly formatted\n",
        "df['Mortality_Status'] = df['Mortality_Status'].replace({'Alive': 0, 'Dead': 1})\n",
        "\n",
        "# in ML we need numbers not text, so we replace text values with numeric ones\n",
        "# Alive becomes 0 and Dead becomes 1\n",
        "# this is part of encodding categorial values into machine frendly numbers\n",
        "\n",
        "# Check Sex column for inconsistent values\n",
        "print(\"\\n Unique values in Sex column in the dataset given:\")\n",
        "print(df['Sex'].value_counts())\n",
        "# we check if the Sex column has only Male and Female or if there are mistakes like 1, M, F, male etc\n",
        "# value_counts will show how many times each type appears so we can see any wrong entry\n",
        "\n",
        "# Fix Sex column if needed (assuming 1 represents Male, Female is correct)\n",
        "df['Sex'] = df['Sex'].replace({1: 'Male'})\n",
        "# sometimes in data we see 1 instead of 'Male', so we fix that here\n",
        "# we use replace to make all 1 values as 'Male'\n",
        "# this makes the data more clean and consistant\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzXbQC9DCmpd",
        "outputId": "24b5efd1-7b6b-454a-eced-8fa4a48e15e6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Unique values in Sex column:\n",
            "Sex\n",
            "Female    3996\n",
            "1           19\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SPEACIAL COLUMN WORK MAKING PART\n",
        "print(\"\\n SPECIAL COLUMN WORK MAKING PART \")\n",
        "\n",
        "# encoding for categorical features\n",
        "categorical_columns = [\n",
        "    'Sex', 'Occupation', 'T_Stage', 'N_Stage', '6th_Stage',\n",
        "    'Differentiated', 'Grade', 'A_Stage', 'Estrogen_Status',\n",
        "    'Progesterone_Status', 'Age_Group'\n",
        "]\n",
        "\n",
        "# here we select all the columns which have text lables or catagories\n",
        "# becose machine learning cant understand text like 'Male', 'Low', etc.\n",
        "# we need to convert them into numeric format by using one hot encoding\n",
        "\n",
        "# Remove 'Mortality_Status' from categorical columns for encoding as it's already numeric\n",
        "df_encoded = pd.get_dummies(df, columns=categorical_columns, drop_first=True)\n",
        "# we use get_dummies to convert the categorial columns into multiple new columns with 0 or 1\n",
        "# drop_first=True is used to avoide dummy trap (like having both Male and Female can cause confusion)\n",
        "# this helps models to train better without multicolinearity problm\n",
        "\n",
        "print(\"\\n Encoded features preview:\")\n",
        "print(df_encoded.head())\n",
        "# we print out the new dataset after encoding to see if the changes are looking fine\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJQ0OteVDOBQ",
        "outputId": "bdb478bd-e11f-4674-8e6c-f64f6a3daf38"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " SPECIAL COLUMN WORK MAKING PART \n",
            "\n",
            " Encoded features preview:\n",
            "  Patient_ID  Month_of_Birth   Age  Tumor_Size  Regional_Node_Examined  \\\n",
            "0      A0012              12  68.0         4.0                    24.0   \n",
            "1      A0013              12  50.0        35.0                    14.0   \n",
            "2      A0014              11  58.0        63.0                    14.0   \n",
            "3      A0015               3  58.0        18.0                     2.0   \n",
            "4      A0016               1  47.0        41.0                     3.0   \n",
            "\n",
            "   Reginol_Node_Positive  Survival_Months Mortality_Status  \\\n",
            "0                      1               60                0   \n",
            "1                      5               62                0   \n",
            "2                      7               75                0   \n",
            "3                      1               84                0   \n",
            "4                      1               50                0   \n",
            "\n",
            "   Reginl_Node_Positive  Sex_Female  ...  Differentiated_Undifferentiated  \\\n",
            "0                     1        True  ...                            False   \n",
            "1                     5        True  ...                            False   \n",
            "2                     7        True  ...                            False   \n",
            "3                     1        True  ...                            False   \n",
            "4                     1        True  ...                            False   \n",
            "\n",
            "   Differentiated_Well differentiated  Grade_2  Grade_3  Grade_4  \\\n",
            "0                               False    False     True    False   \n",
            "1                               False     True    False    False   \n",
            "2                               False     True    False    False   \n",
            "3                               False    False     True    False   \n",
            "4                               False    False     True    False   \n",
            "\n",
            "   A_Stage_Regional  Estrogen_Status_Positive  Progesterone_Status_Positive  \\\n",
            "0              True                      True                          True   \n",
            "1              True                      True                          True   \n",
            "2              True                      True                          True   \n",
            "3              True                      True                          True   \n",
            "4              True                      True                          True   \n",
            "\n",
            "   Age_Group_Middle  Age_Group_Senior  \n",
            "0             False              True  \n",
            "1              True             False  \n",
            "2              True             False  \n",
            "3              True             False  \n",
            "4              True             False  \n",
            "\n",
            "[5 rows x 69 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  CREATE DATASETS FOR MODELING\n",
        "print(\"\\n=== CREATING MODELING DATASETS ===\")\n",
        "\n",
        "#  Classification dataset (predicting the moralitymortality)\n",
        "classification_df = df_encoded.copy()\n",
        "\n",
        "# we make a copy of the full encoded data for classification task\n",
        "# Drop Patient_ID and Survival_Months for classification\n",
        "#fo the classification modelling we use the patiend_id data and survival_months data for perfect understanding\n",
        "classification_df = classification_df.drop(['Patient_ID', 'Survival_Months'], axis=1)\n",
        "\n",
        "# for classification (predicting Dead or Alive), we don’t need Patient_ID and survival time\n",
        "# so we remove them becose they are not helpful or can leak info\n",
        "\n",
        "# Regression dataset (predicting survival months)\n",
        "#make copy og pandas encoded regression task\n",
        "regression_df = df_encoded.copy()\n",
        "# same way we make another copy for regression task (predicting how many months a person survive)\n",
        "# Drop Patient_ID for regression\n",
        "\n",
        "regression_df = regression_df.drop(['Patient_ID'], axis=1)\n",
        "# here we keep 'Survival_Months' because we are going to predict it\n",
        "# but remove Patient_ID again becose it’s just an identifier, not useful for prediction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhpGD57GGHms",
        "outputId": "995c74d9-d7bc-4a8f-cd7b-8c075e7089ad"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== CREATING MODELING DATASETS ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  DEEP DATA LOOKING PART\n",
        "print(\"\\n DEEP DATA LOOKING PART \")\n",
        "\n",
        "#  Classification dataset balance\n",
        "print(\"\\n Classification Target Distribution:\")\n",
        "# Since Mortality_Status is now numeric (0 or 1), we need to adjust how we display it\n",
        "\n",
        "mortality_counts = df['Mortality_Status'].value_counts()\n",
        "\n",
        "print(mortality_counts)\n",
        "\n",
        "print(df['Mortality_Status'].value_counts(normalize=True))\n",
        "# here we checking how many peoples are dead (1) and alive (0) in our dataset\n",
        "# we print normal count and also normalize=True to see in percentage form\n",
        "# this help us to know if the dataset is balance or not (like 70% alive, 30% dead)\n",
        "\n",
        "# Regression target distribution\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "\n",
        "sns.histplot(df['Survival_Months'], kde=True)\n",
        "\n",
        "plt.title('Distribution of Survival Months')\n",
        "\n",
        "# here we plot how survival months are spread in the data\n",
        "# the histplot + kde shows how many peoples lived for how many months\n",
        "# we save the plot in a file so we can use it later in report or anywere\n",
        "\n",
        "plt.xlabel('Survival Months')\n",
        "plt.ylabel('Frequency')\n",
        "plt.savefig(os.path.join(save_path, 'survival_months_distribution.png'))\n",
        "plt.close()\n",
        "\n",
        "#  Correlation analysis\n",
        "plt.figure(figsize=(12, 10))\n",
        "\n",
        "numerical_columns = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "correlation = df[numerical_columns].corr()\n",
        "\n",
        "sns.heatmap(correlation, annot=True, cmap='coolwarm', fmt='.2f')\n",
        "\n",
        "\n",
        "\n",
        "# here we checking how the numeric columns are related to each other\n",
        "# like does Age and Survival have strong relation or not\n",
        "# the heatmap shows red and blue color where red means high positive correlation and blue means negative\n",
        "# annot=True will print numbers inside the boxes for better understand\n",
        "\n",
        "plt.title('Correlation Matrix of Numerical Features')\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(save_path, 'correlation_matrix.png'))\n",
        "plt.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26FcKCGKKcu3",
        "outputId": "c741906f-0799-41d2-bdcd-647e25d595a7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " DEEP DATA LOOKING PART \n",
            "\n",
            " Classification Target Distribution:\n",
            "Mortality_Status\n",
            "0        3395\n",
            "1         597\n",
            "DEAD       10\n",
            "dead        8\n",
            "ALIVE       5\n",
            "alive       3\n",
            "ALive       1\n",
            "Name: count, dtype: int64\n",
            "Mortality_Status\n",
            "0        0.844737\n",
            "1        0.148544\n",
            "DEAD     0.002488\n",
            "dead     0.001991\n",
            "ALIVE    0.001244\n",
            "alive    0.000746\n",
            "ALive    0.000249\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " #AVE PROCESSED DATASETS for the classification and regression in csv format\n",
        "print(\"\\n=== SAVING PROCESSED DATASETS ===\")\n",
        "\n",
        "# Save classification dataset\n",
        "classification_df.to_csv(os.path.join(save_path, 'classification_dataset_final.csv'), index=False)\n",
        "print(f\"Classification dataset saved with shape: {classification_df.shape}\")\n",
        "\n",
        "# Save regression dataset\n",
        "regression_df.to_csv(os.path.join(save_path, 'regression_dataset_final.csv'), index=False)\n",
        "print(f\"Regression dataset saved with shape: {regression_df.shape}\")\n",
        "\n",
        "print(\"\\nPreprocessing completed. Datasets saved to:\", save_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWABPiuXDR1O",
        "outputId": "2b9de2c5-8ec7-4d40-95f6-c8450744c2de"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== SAVING PROCESSED DATASETS ===\n",
            "Classification dataset saved with shape: (4019, 66)\n",
            "Regression dataset saved with shape: (4019, 67)\n",
            "\n",
            "Preprocessing completed. Datasets saved to: /content/drive/MyDrive/Machine_Learning_CourseWork\n"
          ]
        }
      ]
    }
  ]
}