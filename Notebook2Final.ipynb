{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1sZS10q9gpZPa8Ijlt6Gejhoi6Ehdsj--",
      "authorship_tag": "ABX9TyP/2JMDzDXukDGotZTdbbbS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thaheshan/Breast_Cancer_Prediction_Model/blob/main/Notebook2Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Title: Notebook 2 - Classification and Regression Models for Cancer Survival Analysis\n",
        "# Author: Suresh Thaheshan\n",
        "# Peer Reviewer: Ayman Jaleel\n",
        "# Date: March,  11, 2025\n",
        "\n",
        "\n",
        "\n",
        "# IMPORT LIBRARIES\n",
        "# Import the libraries for the necessary inputs related clssification regression modelling and preprocess the regression modellig\n",
        "\n",
        "#code reuse for import from notebok 01 reuse\n",
        "#import pandas library\n",
        "#which is very important for loading te datset , cleaning and manipulation\n",
        "#it will manipulate the dataset and analyze the survival prediction\n",
        "import pandas as pd\n",
        "\n",
        "#import numpy library for thenumerical operation\n",
        "#it is usefuk for calculations in math opeartions\n",
        "import numpy as np\n",
        "\n",
        "#import mathplotlib for the creative visualizaations\n",
        "#it will give the data analysis in visualization graph and tables\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#import seadborn to use this with matplotlib library\n",
        "#it will be helpul for, statistical graaphic and for the distribution plots\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "\n",
        "# Importing joblib for saving and loading models.\n",
        "# joblib helps in serializing and deserializing models, enabling saving of trained models.\n",
        "import joblib\n",
        "\n",
        "\n",
        "# Importing model selection tools for splitting data, cross-validation, and hyperparameter tuning.\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "\n",
        "# Importing ensemble models for classification and regression.\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "\n",
        "# Importing performance evaluation metrics.\n",
        "from sklearn.metrics import (\n",
        "    classification_report, confusion_matrix, accuracy_score, roc_auc_score,\n",
        "    roc_curve, mean_squared_error, r2_score, mean_absolute_error\n",
        ")\n",
        "\n",
        "# Importing data preprocessing tools.\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Importing the Pipeline module to streamline preprocessing and model training.\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Importing SimpleImputer for handling missing data.\n",
        "from sklearn.impute import SimpleImputer\n"
      ],
      "metadata": {
        "id": "RwDUqV2us25f"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set visualization style\n",
        "sns.set_style('whitegrid')\n",
        "# Sets the style of seaborn visualizations. The 'whitegrid' style is chosen for clean background and gridlines which helps with readability of the data.\n",
        "\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "# Applies the seaborn style from matplotlib for consistent plot appearances. This is helpful for both seaborn and matplotlib plots, keeping a uniform style throughout the notebook.\n",
        "\n",
        "# Define save path\n",
        "save_path = '/content/drive/MyDrive/Machine_Learning_CourseWork'\n",
        "# Defines the directory where the plots, models, and other results will be saved. This path is set to Google Drive (for Colab users), but can be customized to any path.\n",
        "\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "# Creates the directory specified by 'save_path'. If the directory already exists, it does nothing (thanks to the 'exist_ok=True' argument).\n",
        "# Ensures that the directory exists for saving outputs, avoiding errors if the directory is not already there.\n"
      ],
      "metadata": {
        "id": "itxsv_hgLu74"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#---------------- LOAD the preprocessed data into this system---------------\n",
        "# Previously we saved it with notebook 01\n",
        "print(\"---------------Loading processed datasets from notebook 01----------\")\n",
        "\n",
        "# Load the preprocessed classification file\n",
        "classification_df = pd.read_csv(os.path.join(save_path, 'classification_dataset.csv'))\n",
        "# Loads the preprocessed classification dataset that was saved earlier from notebook 01.\n",
        "# The 'pd.read_csv' method is used to read the CSV file from the specified save_path.\n",
        "\n",
        "# Load the preprocessed regression data file\n",
        "regression_df = pd.read_csv(os.path.join(save_path, 'regression_dataset.csv'))\n",
        "# Loads the preprocessed regression dataset that was saved earlier from notebook 01.\n",
        "\n",
        "# Display the shape of both datasets\n",
        "print(f\"Classification dataset shape: {classification_df.shape}\")\n",
        "# Prints the shape (number of rows and columns) of the classification dataset.\n",
        "\n",
        "print(f\"Regression dataset shape: {regression_df.shape}\")\n",
        "# Prints the shape (number of rows and columns) of the regression dataset.\n",
        "\n",
        "# Display the columns of the classification dataset\n",
        "print(\"\\nClassification dataset columns:\")\n",
        "print(classification_df.columns.tolist())\n",
        "# Prints the column names of the classification dataset in a list format.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CiuDMSuCMKBl",
        "outputId": "8775dd05-d2d0-4bce-baa2-d9ebb78eaced"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------Loading processed datasets from notebook 01----------\n",
            "Classification dataset shape: (4019, 66)\n",
            "Regression dataset shape: (4019, 67)\n",
            "\n",
            "Classification dataset columns:\n",
            "['Month_of_Birth', 'Age', 'Tumor_Size', 'Regional_Node_Examined', 'Reginol_Node_Positive', 'Mortality_Status', 'Sex_Female', 'Occupation_Agriculture', 'Occupation_Arts', 'Occupation_Business', 'Occupation_Cleaning', 'Occupation_Construction', 'Occupation_Consultancy', 'Occupation_Design', 'Occupation_Development', 'Occupation_Driving', 'Occupation_Engineering', 'Occupation_Entertainment', 'Occupation_Finance', 'Occupation_Healthcare', 'Occupation_Hospitality', 'Occupation_House Person', 'Occupation_Human Resources', 'Occupation_Legal', 'Occupation_Leisure', 'Occupation_Maintenance', 'Occupation_Management', 'Occupation_Manufacturing', 'Occupation_Marketing', 'Occupation_Medical', 'Occupation_Military', 'Occupation_Multimedia', 'Occupation_Photography', 'Occupation_Planning', 'Occupation_Politics', 'Occupation_Public', 'Occupation_Reporting', 'Occupation_Research', 'Occupation_Sales', 'Occupation_Scoial work', 'Occupation_Sports', 'Occupation_Teaching', 'Occupation_Technology', 'Occupation_Trading', 'Occupation_Training', 'Occupation_Travel', 'T_Stage_T2', 'T_Stage_T3', 'T_Stage_T4', 'N_Stage_N2', 'N_Stage_N3', '6th_Stage_IIB', '6th_Stage_IIIA', '6th_Stage_IIIB', '6th_Stage_IIIC', 'Differentiated_Poorly differentiated', 'Differentiated_Undifferentiated', 'Differentiated_Well differentiated', 'Grade_2', 'Grade_3', 'Grade_4', 'A_Stage_Regional', 'Estrogen_Status_Positive', 'Progesterone_Status_Positive', 'Age_Group_Middle', 'Age_Group_Senior']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------CHECK FOR MISSING VALUES-----------------\n",
        "# This section checks the missing values in both datasets\n",
        "\n",
        "print(\"\\n ----- CHECKING FOR THE MISSING VALUES ---------\")\n",
        "\n",
        "# Check for missing values in the classification dataset\n",
        "print(f\"Classification dataset missing values: {classification_df.isna().sum().sum()}\")\n",
        "# The 'isna().sum().sum()' function calculates the total number of missing values in the entire classification dataset.\n",
        "\n",
        "# Check for missng values in the regression dataset\n",
        "print(f\"Regression dataset missing values: {regression_df.isna().sum().sum()}\")\n",
        "# Similarly, checks the total number of missing values in the regression dataset.\n",
        "\n",
        "# Check which columns have missing values in the classificaiion dataset\n",
        "print(\"\\nColumns with missing values in classification dataset:\")\n",
        "missing_cols = classification_df.columns[classification_df.isna().any()].tolist()\n",
        "# 'isna().any()' finds columns with at least one missing value. The columns are then listed using '.columns' and converted to a list.\n",
        "\n",
        "# Print out each column with its count of missing values\n",
        "for col in missing_cols:\n",
        "    missing_count = classification_df[col].isna().sum()\n",
        "    print(f\"- {col}: {missing_count} missing values ({missing_count/len(classification_df)*100:.2f}%)\")\n",
        "    # For each column with missing values, it prints the number of missing values and the percentage of missing data.\n",
        "\n",
        "# CLEAN UP MORTALITY STATUS VALUES\n",
        "# This section ensures the Mortality Status values are standardized\n",
        "\n",
        "print(\"\\n=== CLEANING MORTALITY STATUS VALUES ===\")\n",
        "print(\"\\nInitial Mortality Status values:\")\n",
        "print(classification_df['Mortality_Status'].value_counts())\n",
        "# This shows the initial distribution of values in the 'Mortality_Status' column before cleaning.\n",
        "\n",
        "# Mapping different representations of Mortality Status to consistent values (0 for alive, 1 for dead)\n",
        "mortality_mapping = {\n",
        "    0: 0, '0': 0, 'ALIVE': 0, 'alive': 0, 'ALive': 0, 'Alive': 0,\n",
        "    1: 1, '1': 1, 'DEAD': 1, 'dead': 1, 'Dead': 1\n",
        "}\n",
        "# A dictionary is created to map all variations of 'alive' and 'dead' to the standardized values of 0 and 1, respectively.\n",
        "\n",
        "# Apply the mapping to both datasets\n",
        "classification_df['Mortality_Status'] = classification_df['Mortality_Status'].map(mortality_mapping)\n",
        "regression_df['Mortality_Status'] = regression_df['Mortality_Status'].map(mortality_mapping)\n",
        "# The mapping is applied to both datasets' 'Mortality_Status' columns to ensure consistent values.\n",
        "\n",
        "# Ensure that the Mortality Status is of integer type\n",
        "classification_df['Mortality_Status'] = classification_df['Mortality_Status'].astype(int)\n",
        "regression_df['Mortality_Status'] = regression_df['Mortality_Status'].astype(int)\n",
        "# Converts the 'Mortality_Status' column to integers after cleaning.\n",
        "\n",
        "# Show the cleaned Mortality Status values\n",
        "print(\"\\nCleaned Mortality Status values:\")\n",
        "print(classification_df['Mortality_Status'].value_counts())\n",
        "print(classification_df['Mortality_Status'].value_counts(normalize=True))\n",
        "# Displays the distribution of 'Mortality_Status' after cleaning, both as a count and as a normalized percentage.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RrM5nM_MjL9",
        "outputId": "b2e0d33a-fecf-4d0d-de61-a6276970d57b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " ----- CHECKING FOR THE MISSING VALUES ---------\n",
            "Classification dataset missing values: 1\n",
            "Regression dataset missing values: 1\n",
            "\n",
            "Columns with missing values in classification dataset:\n",
            "- Regional_Node_Examined: 1 missing values (0.02%)\n",
            "\n",
            "=== CLEANING MORTALITY STATUS VALUES ===\n",
            "\n",
            "Initial Mortality Status values:\n",
            "Mortality_Status\n",
            "0        3395\n",
            "1         597\n",
            "DEAD       10\n",
            "dead        8\n",
            "ALIVE       5\n",
            "alive       3\n",
            "ALive       1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Cleaned Mortality Status values:\n",
            "Mortality_Status\n",
            "0    3404\n",
            "1     615\n",
            "Name: count, dtype: int64\n",
            "Mortality_Status\n",
            "0    0.846977\n",
            "1    0.153023\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#----------- CLASSIFICATION PREPROCESSING -----------------------------\n",
        "# This section preprocesses the data for the classification model\n",
        "\n",
        "print(\"\\n ----------- CLASSIFICATION MODEL PREPROCESSING ---------------------\")\n",
        "\n",
        "# Separate features and target variable from the classification dataset\n",
        "X_class = classification_df.drop(columns=['Mortality_Status'])  # Drop the target variable column 'Mortality_Status' for features\n",
        "y_class = classification_df['Mortality_Status']  # Assign the target variable to y_class\n",
        "\n",
        "# Split the data into training and testing sets (80% train, 20% test)\n",
        "X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(\n",
        "    X_class, y_class, test_size=0.2, stratify=y_class, random_state=42\n",
        ")\n",
        "# train_test_split randomly splits the data into training and testing sets\n",
        "# stratify ensures that the target variable's distribution is maintained in both train and test sets\n",
        "# random_state=42 ensures reproducibility of the results\n",
        "\n",
        "# Define a pipeline to preprocess the data for classification\n",
        "classification_pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='median')),  # Handle missing values by replacing them with the median\n",
        "    ('scaler', StandardScaler())  # Standardize the features by scaling them to have a mean of 0 and a standard deviation of 1\n",
        "])\n",
        "# The pipeline ensures that the preprocessing steps are applied sequentially on the dataset\n",
        "\n",
        "# Apply the pipeline to transform the training data\n",
        "X_train_class_processed = classification_pipeline.fit_transform(X_train_class)\n",
        "# 'fit_transform' fits the imputer and scaler to the training data, then applies the transformations\n",
        "\n",
        "# Apply the pipeline to transform the test data using the same transformations learned from the training data\n",
        "X_test_class_processed = classification_pipeline.transform(X_test_class)\n",
        "# 'transform' uses the already learned transformations from the training data to scale the test data\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKUESYsJNJfX",
        "outputId": "4c9f9b48-52f0-40f1-d80d-20b1fc563d4a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== CLASSIFICATION MODEL PREPROCESSING ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#-------------- CLASSIFICATION MODELS------------------------------\n",
        "# This section trains and evaluates the logistic regression model for classification\n",
        "\n",
        "print(\"\\n=== LOGISTIC REGRESSION MODEL ===\")\n",
        "\n",
        "# Create and train a Logistic Regression model\n",
        "# 'max_iter=1000' ensures that the solver has enough iterations to converge\n",
        "# 'random_state=42' ensures reproducibility\n",
        "# 'class_weight=\"balanced\"' adjusts weights to handle class imbalance in the target variable\n",
        "log_model = LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced')\n",
        "\n",
        "# Fit the logistic regression model on the preprocessed training data\n",
        "log_model.fit(X_train_class_processed, y_train_class)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_log = log_model.predict(X_test_class_processed)\n",
        "\n",
        "# Print confusion matrix to show the number of correct/incorrect predictions for each class\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test_class, y_pred_log))\n",
        "\n",
        "# Print classification report to show precision, recall, f1-score, and support for each class\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_class, y_pred_log))\n",
        "\n",
        "# Print the accuracy score of the model\n",
        "print(\"Accuracy Score:\", accuracy_score(y_test_class, y_pred_log))\n",
        "\n",
        "# Perform cross-validation to evaluate the model using 5-fold cross-validation\n",
        "cv_scores_log = cross_val_score(\n",
        "    Pipeline([  # Create a pipeline with preprocessing steps and the logistic regression model\n",
        "        ('imputer', SimpleImputer(strategy='median')),  # Impute missing values with the median\n",
        "        ('scaler', StandardScaler()),  # Standardize features to have zero mean and unit variance\n",
        "        ('model', LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced'))  # Logistic regression model\n",
        "    ]),\n",
        "    X_train_class, y_train_class, cv=5  # Perform 5-fold cross-validation on the training set\n",
        ")\n",
        "\n",
        "# Print the cross-validation scores\n",
        "print(f\"\\nCross-validation scores (Logistic Regression): {cv_scores_log}\")\n",
        "\n",
        "# Print the average cross-validation accuracy\n",
        "print(f\"Average CV accuracy: {cv_scores_log.mean():.4f}\")\n",
        "\n",
        "# Get the probabilities of the positive class (class 1) for ROC curve plotting\n",
        "y_probs_log = log_model.predict_proba(X_test_class_processed)[:, 1]\n",
        "\n",
        "# Calculate the false positive rate and true positive rate for ROC curve\n",
        "fpr_log, tpr_log, _ = roc_curve(y_test_class, y_probs_log)\n",
        "\n",
        "# Calculate the area under the ROC curve (AUC)\n",
        "auc_log = roc_auc_score(y_test_class, y_probs_log)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFIr8sNDNU8Q",
        "outputId": "b88969aa-d82e-44cb-8500-db49a26661ed"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== LOGISTIC REGRESSION MODEL ===\n",
            "\n",
            "Confusion Matrix:\n",
            "[[469 212]\n",
            " [ 45  78]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.69      0.78       681\n",
            "           1       0.27      0.63      0.38       123\n",
            "\n",
            "    accuracy                           0.68       804\n",
            "   macro avg       0.59      0.66      0.58       804\n",
            "weighted avg       0.81      0.68      0.72       804\n",
            "\n",
            "Accuracy Score: 0.6803482587064676\n",
            "\n",
            "Cross-validation scores (Logistic Regression): [0.74183515 0.70606532 0.68429238 0.72939347 0.69984448]\n",
            "Average CV accuracy: 0.7123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot ROC curve for Logistic Regression model performance\n",
        "# This section generates and saves the ROC curve plot\n",
        "\n",
        "plt.figure(figsize=(8, 5))  # Set figure size\n",
        "plt.plot(fpr_log, tpr_log, label=f'Logistic Regresion (AUC = {auc_log:.2f})')  # Plot ROC curve with label showing AUC value\n",
        "plt.plot([0, 1], [0, 1], 'k--')  # Plot diagonal line (no discrimination line)\n",
        "plt.xlabel('False Positive Rate')  # Label for x-axis\n",
        "plt.ylabel('True Positive Rate')  # Label for y-axis\n",
        "plt.title('ROC Curve - Logistic Regresion')  # Title of the plot\n",
        "plt.legend()  # Show legend for the curve\n",
        "plt.grid(True)  # Add grid lines for easier reading\n",
        "plt.savefig(os.path.join(save_path, 'log_reg_roc_curve.png'))  # Save the plot as a PNG file\n",
        "plt.close()  # Close the plot to free memory\n",
        "\n",
        "# Plot confusion matrix for Logistic Regression model performance\n",
        "# This section generates and saves the confusion matrix heatmap\n",
        "\n",
        "plt.figure(figsize=(6, 4))  # Set figure size\n",
        "sns.heatmap(confusion_matrix(y_test_class, y_pred_log), annot=True, fmt='d', cmap='Blues')  # Plot heatmap of confusion matrix with annotations\n",
        "plt.title('Confusion Matrix - Logistic Regresion')  # Title of the heatmap\n",
        "plt.xlabel('Predicted')  # Label for x-axis\n",
        "plt.ylabel('Actual')  # Label for y-axis\n",
        "plt.savefig(os.path.join(save_path, 'log_reg_confusion_matrix.png'))  # Save the heatmap as a PNG file\n",
        "plt.close()  # Close the plot to free memory\n"
      ],
      "metadata": {
        "id": "1GFVKhSCNr7P"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RANDOM FOREST CLASSIFIER\n",
        "\n",
        "# Print the starting message for the Random Forest Classifier model\n",
        "print(\"\\n ------------ RANDOM FOREST CLASSIFIER ------------------------------------\")\n",
        "\n",
        "# Create a pipeline with imputation and Random Forest Classifier\n",
        "# The pipeline will first fill missing values with median, then apply the Random Forest Classifier\n",
        "rf_pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='median')),  # Use median to handle missing data\n",
        "    ('model', RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced'))  # Initialize RandomForestClassifier\n",
        "])\n",
        "\n",
        "# Fit the Random Forest pipeline on the training data\n",
        "rf_pipeline.fit(X_train_class, y_train_class)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_rf = rf_pipeline.predict(X_test_class)\n",
        "\n",
        "# Extract the Random Forest model from the pipeline\n",
        "rf_model = rf_pipeline.named_steps['model']\n",
        "\n",
        "# Print the confusion matrix to evaluate the classification performance\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test_class, y_pred_rf))\n",
        "\n",
        "# Print the classification report to get detailed metrics (precision, recall, f1-score)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_class, y_pred_rf))\n",
        "\n",
        "# Print the accuracy score for the model's performance\n",
        "print(\"Accuracy Score:\", accuracy_score(y_test_class, y_pred_rf))\n",
        "\n",
        "# Create a DataFrame to display the feature importances for the Random Forest model\n",
        "# This will help to identify which features contribute most to the model's predictions\n",
        "feature_importance_df = pd.DataFrame({\n",
        "    'Feature': X_train_class.columns,  # Features in the training dataset\n",
        "    'Importance': rf_model.feature_importances_  # Importance of each feature calculated by the Random Forest model\n",
        "}).sort_values(by='Importance', ascending=False)  # Sort features by importance in descending order\n",
        "\n",
        "# Plot the top 20 features with the highest importance\n",
        "plt.figure(figsize=(12, 8))\n",
        "# Set figure size\n",
        "\n",
        "\n",
        "sns.barplot(x='Importance', y='Feature', data=feature_importance_df.head(20))\n",
        "# Plot the barplots\n",
        "\n",
        "\n",
        "plt.title('Top 20 Random Forest Feature Importances (Classification)')\n",
        "# Title for the plots\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "# Adjust layout to avoid overlap\n",
        "\n",
        "\n",
        "plt.savefig(os.path.join(save_path, 'rf_feature_importance.png'))\n",
        " # Save the plot to the speccified dirctory\n",
        "\n",
        "\n",
        "plt.close()\n",
        " # Close the plot to free memory\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rU9HDt-yONp7",
        "outputId": "a022a077-cef9-4605-962c-6bc41cba565d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== RANDOM FOREST CLASSIFIER ===\n",
            "\n",
            "Confusion Matrix:\n",
            "[[665  16]\n",
            " [110  13]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.98      0.91       681\n",
            "           1       0.45      0.11      0.17       123\n",
            "\n",
            "    accuracy                           0.84       804\n",
            "   macro avg       0.65      0.54      0.54       804\n",
            "weighted avg       0.80      0.84      0.80       804\n",
            "\n",
            "Accuracy Score: 0.8432835820895522\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PREDICTIONS AND ROC CURVE COMPARISON\n",
        "\n",
        "# Get the predicted probabilities for the Random Forest Classifier model\n",
        "# '[:, 1]' extracts the probabilities for the positive class (1) in a binary classification\n",
        "y_probs_rf = rf_pipeline.predict_proba(X_test_class)[:, 1]\n",
        "\n",
        "# Compute the false positive rate and true positive rate for the Random Forest model\n",
        "fpr_rf, tpr_rf, _ = roc_curve(y_test_class, y_probs_rf)\n",
        "\n",
        "# Calculate the AUC (Area Under the Curve) score for the Random Forest model\n",
        "auc_rf = roc_auc_score(y_test_class, y_probs_rf)\n",
        "\n",
        "# Plot ROC curves for both Logistic Regression and Random Forest models\n",
        "# Set up the figure size for the plot\n",
        "plt.figure(figsize=(8, 5))\n",
        "\n",
        "# Plot ROC curve for Logistic Regression (already calculated in previous steps)\n",
        "plt.plot(fpr_log, tpr_log, label=f'Logistic Regression (AUC = {auc_log:.2f})')\n",
        "\n",
        "# Plot ROC curve for Random Forest, using a dashed line for distinction\n",
        "plt.plot(fpr_rf, tpr_rf, label=f'Random Forest (AUC = {auc_rf:.2f})', linestyle='--')\n",
        "\n",
        "# Plot the diagonal line representing a random classifier (AUC = 0.5)\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "\n",
        "# Label the axes of the plot\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "\n",
        "# Add a title for the plot\n",
        "plt.title('ROC Curve Comparison')\n",
        "\n",
        "# Display the legend showing the models and their AUC values\n",
        "plt.legend()\n",
        "\n",
        "# Enable the grid for better readability of the plot\n",
        "plt.grid(True)\n",
        "\n",
        "# Save the ROC curve comparison plot to the specified save path\n",
        "plt.savefig(os.path.join(save_path, 'roc_curve_comparison.png'))\n",
        "\n",
        "# Close the plot to release memory\n",
        "plt.close()\n"
      ],
      "metadata": {
        "id": "1U8-OUVoPAv2"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# REGRESSION PREPROCESSING ===\n",
        "# Start by printing the message indicating the start of the Regression model preprocessing step\n",
        "print(\"\\n=== REGRESSION MODEL PREPROCESSING ===\")\n",
        "\n",
        "# Separate the feature set (X) and target variable (y) for regression\n",
        "# We drop 'Survival_Months' and 'Mortality_Status' from the features as 'Survival_Months' is the target variable\n",
        "X_reg = regression_df.drop(columns=['Survival_Months', 'Mortality_Status'])\n",
        "y_reg = regression_df['Survival_Months']\n",
        "\n",
        "# Display basic statistics (like mean, min, max, etc.) for the 'Survival_Months' column\n",
        "# This helps in understanding the distribution and range of the target variable\n",
        "print(\"\\nSurvival Months Statistics:\")\n",
        "print(y_reg.describe())\n",
        "\n",
        "# Split the dataset into training and testing sets (80% for training, 20% for testing)\n",
        "# The split ensures that we have separate data for training the model and for evaluating its performance\n",
        "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
        "    X_reg, y_reg, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Create a pipeline for data preprocessing for regression\n",
        "# The pipeline includes an imputer to handle missing values and a scaler to standardize the data\n",
        "regression_pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='median')),  # Imputer replaces missing values with the median of the column\n",
        "    ('scaler', StandardScaler())  # Scaler standardizes the features to have mean = 0 and variance = 1\n",
        "])\n",
        "\n",
        "# Fit and transform the training data using the pipeline\n",
        "# The fit_transform method applies both imputation and scaling to the training set\n",
        "X_train_reg_processed = regression_pipeline.fit_transform(X_train_reg)\n",
        "\n",
        "# Transform the test data using the same imputation and scaling (without fitting it again)\n",
        "# This ensures that the test set is processed in the same way as the training set\n",
        "X_test_reg_processed = regression_pipeline.transform(X_test_reg)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QU3SHGK4PYg_",
        "outputId": "78c97157-0cd3-4075-ff53-2bfa210bfeb0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== REGRESSION MODEL PREPROCESSING ===\n",
            "\n",
            "Survival Months Statistics:\n",
            "count    4019.000000\n",
            "mean       71.476487\n",
            "std        25.367123\n",
            "min         1.000000\n",
            "25%        56.000000\n",
            "50%        73.000000\n",
            "75%        90.000000\n",
            "max       760.000000\n",
            "Name: Survival_Months, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =------------------ REGRESSION MODELS ----------------------------------\n",
        "# Print the message indicating the start of the Regression models section\n",
        "print(\"\\n --------------- REGRESSION MODELS------------------------------ \")\n",
        "\n",
        "# Linear Regression\n",
        "# Print the message indicating the Linear Regression model is being trained and evaluated\n",
        "print(\"\\n    --- Linear Regresion Model ---\")\n",
        "\n",
        "# Initialize the Linear Regression model\n",
        "# lin_reg_model is created as an instance of the LinearRegression class\n",
        "lin_reg_model = LinearRegression()\n",
        "\n",
        "# Fit the Linear Regression model to the training data\n",
        "# The model is trained using the processed training features (X_train_reg_processed) and the target variable (y_train_reg)\n",
        "lin_reg_model.fit(X_train_reg_processed, y_train_reg)\n",
        "\n",
        "# Make predictions on the test data using the trained model\n",
        "# y_pred_lin stores the predicted survival months values based on the test features (X_test_reg_processed)\n",
        "y_pred_lin = lin_reg_model.predict(X_test_reg_processed)\n",
        "\n",
        "# Calculate the performance metrics for the Linear Regression model\n",
        "# mse_lin: Mean Squared Error, mae_lin: Mean Absolute Error, r2_lin: R-squared score\n",
        "mse_lin = mean_squared_error(y_test_reg, y_pred_lin)\n",
        "mae_lin = mean_absolute_error(y_test_reg, y_pred_lin)\n",
        "r2_lin = r2_score(y_test_reg, y_pred_lin)\n",
        "\n",
        "# Print the evaluation metrics for the Linear Regression model\n",
        "print(f\"Mean Squared Error: {mse_lin:.2f}\")\n",
        "print(f\"Mean Absolute Error: {mae_lin:.2f}\")\n",
        "print(f\"R^2 Score: {r2_lin:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrkgsA3gPdln",
        "outputId": "ab7e7407-3c56-4bf7-a580-c4d603ea878e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " --------------- REGRESSION MODELS------------------------------ \n",
            "\n",
            "    --- Linear Regresion Model ---\n",
            "Mean Squared Error: 509.32\n",
            "Mean Absolute Error: 18.54\n",
            "R^2 Score: 0.05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross-validation for Linear Regression\n",
        "# Perform cross-validation on the Linear Regression model to evaluate its performance across multiple folds\n",
        "cv_scores_reg = cross_val_score(\n",
        "    LinearRegression(),  # The model to evaluate\n",
        "    X_train_reg_processed,  # The processed training data\n",
        "    y_train_reg,  # The target variable\n",
        "    scoring='r2',  # Scoring metric (R² score)\n",
        "    cv=5  # Number of folds (5-fold cross-validation)\n",
        ")\n",
        "\n",
        "# Print the cross-validation R² scores for each fold\n",
        "print(f\"Cross-Validation R² Scores: {cv_scores_reg}\")\n",
        "# Print the average R² score across all folds\n",
        "print(f\"Average R²: {cv_scores_reg.mean():.4f}\")\n",
        "\n",
        "# Random Forest Regressor\n",
        "# Print the message indicating the Random Forest Regressor model is being trained and evaluated\n",
        "print(\"\\n--- Random Forst Regressor ---\")\n",
        "\n",
        "# Initialize the Random Forest Regressor model\n",
        "# rf_reg_model is created as an instance of the RandomForestRegressor class\n",
        "rf_reg_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "# Fit the Random Forest Regressor model to the training data\n",
        "# The model is trained using the processed training features (X_train_reg_processed) and the target variable (y_train_reg)\n",
        "rf_reg_model.fit(X_train_reg_processed, y_train_reg)\n",
        "\n",
        "# Make predictions on the test data using the trained model\n",
        "# y_pred_rf_reg stores the predicted survival months values based on the test features (X_test_reg_processed)\n",
        "y_pred_rf_reg = rf_reg_model.predict(X_test_reg_processed)\n",
        "\n",
        "# Calculate the performance metrics for the Random Forest Regressor model\n",
        "# mse_rf: Mean Squared Error, mae_rf: Mean Absolute Error, r2_rf: R-squared score\n",
        "mse_rf = mean_squared_error(y_test_reg, y_pred_rf_reg)\n",
        "mae_rf = mean_absolute_error(y_test_reg, y_pred_rf_reg)\n",
        "r2_rf = r2_score(y_test_reg, y_pred_rf_reg)\n",
        "\n",
        "# Print the evaluation metrics for the Random Forest Regressor model\n",
        "print(f\"Random Forest - MSE: {mse_rf:.2f}\")\n",
        "print(f\"Random Forest - MAE: {mae_rf:.2f}\")\n",
        "print(f\"Random Forest - R^2 Score: {r2_rf:.2f}\")\n",
        "\n",
        "# Feature Importances for Regression\n",
        "# Create a bar plot to show the feature importances of the Random Forest Regressor model\n",
        "# This helps identify which features are most influential in predicting survival months\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.barplot(x=rf_reg_model.feature_importances_, y=X_train_reg.columns)\n",
        "plt.title(\"Feature Importances - Random Forst Regressor\")  # Title with a spelling mistake: 'Forst' instead of 'Forest'\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(save_path, 'rf_reg_feature_importance.png'))\n",
        "plt.close()\n",
        "\n",
        "# Predicted vs Actual Plot\n",
        "# Create a scatter plot to compare the actual vs predicted survival months for the Random Forest Regressor model\n",
        "# This helps visualize how well the model's predictions match the actual data\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.scatterplot(x=y_test_reg, y=y_pred_rf_reg, alpha=0.6)\n",
        "plt.xlabel('Actual Survival Months')\n",
        "plt.ylabel('Predicted Survival Months')\n",
        "plt.title('Actual vs Predicted - Random Forest Regressor')\n",
        "plt.grid(True)\n",
        "plt.savefig(os.path.join(save_path, 'rf_reg_actual_vs_predicted.png'))\n",
        "plt.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tkhp0yhIsI3",
        "outputId": "6874aa87-f159-4710-d2ef-148c7422ca3d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation R² Scores: [ 0.00142027  0.02845832  0.01234979 -0.00081983  0.01798137]\n",
            "Average R²: 0.0119\n",
            "\n",
            "--- Random Forst Regressor ---\n",
            "Random Forest - MSE: 544.69\n",
            "Random Forest - MAE: 19.01\n",
            "Random Forest - R^2 Score: -0.02\n"
          ]
        }
      ]
    }
  ]
}